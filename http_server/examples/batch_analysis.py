#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
KataGo HTTPæœåŠ¡æ‰¹é‡åˆ†æç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•æ‰¹é‡åˆ†æå¤šä¸ªæ£‹å±€æˆ–ä½ç½®

ä½¿ç”¨æ–¹æ³•:
    python batch_analysis.py [--host HOST] [--port PORT] [--input INPUT_FILE] [--output OUTPUT_FILE]
"""

import argparse
import json
import requests
import time
import csv
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Any, List, Optional
from dataclasses import dataclass


@dataclass
class AnalysisJob:
    """åˆ†æä»»åŠ¡"""
    id: str
    moves: List[List[str]]
    board_size: int = 19
    komi: float = 7.5
    rules: str = "tromp-taylor"
    max_visits: int = 1000
    description: str = ""


class BatchAnalyzer:
    """æ‰¹é‡åˆ†æå™¨"""
    
    def __init__(self, host: str = "localhost", port: int = 8080, timeout: int = 60):
        self.host = host
        self.port = port
        self.timeout = timeout
        self.base_url = f"http://{host}:{port}"
        self.session = requests.Session()
        self.session.timeout = timeout
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_jobs = 0
        self.completed_jobs = 0
        self.failed_jobs = 0
        self.start_time = None
        
    def analyze_single_position(self, job: AnalysisJob) -> Optional[Dict[str, Any]]:
        """åˆ†æå•ä¸ªä½ç½®"""
        request_data = {
            "id": job.id,
            "moves": job.moves,
            "rules": job.rules,
            "komi": job.komi,
            "boardXSize": job.board_size,
            "boardYSize": job.board_size,
            "analyzeTurns": [len(job.moves)],
            "maxVisits": job.max_visits,
            "includeOwnership": True,
            "includePVVisits": True
        }
        
        try:
            start_time = time.time()
            response = self.session.post(
                f"{self.base_url}/analyze",
                json=request_data,
                headers={"Content-Type": "application/json"}
            )
            end_time = time.time()
            
            if response.status_code == 200:
                result = response.json()
                result["analysis_time"] = end_time - start_time
                result["job_description"] = job.description
                return result
            else:
                print(f"âŒ åˆ†æå¤±è´¥ {job.id}: HTTP {response.status_code}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥ {job.id}: {e}")
            return None
    
    def analyze_batch(self, jobs: List[AnalysisJob], max_workers: int = 4) -> List[Dict[str, Any]]:
        """æ‰¹é‡åˆ†æ"""
        self.total_jobs = len(jobs)
        self.completed_jobs = 0
        self.failed_jobs = 0
        self.start_time = time.time()
        
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ")
        print(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {self.total_jobs}")
        print(f"ğŸ”§ å¹¶å‘æ•°: {max_workers}")
        print(f"ğŸŒ æœåŠ¡åœ°å€: {self.base_url}")
        print("-" * 50)
        
        results = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_job = {executor.submit(self.analyze_single_position, job): job for job in jobs}
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_job):
                job = future_to_job[future]
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                        self.completed_jobs += 1
                        print(f"âœ… å®Œæˆ {job.id} ({self.completed_jobs}/{self.total_jobs}) - "
                              f"è€—æ—¶: {result.get('analysis_time', 0):.2f}s")
                    else:
                        self.failed_jobs += 1
                        print(f"âŒ å¤±è´¥ {job.id} ({self.failed_jobs} ä¸ªå¤±è´¥)")
                        
                except Exception as e:
                    self.failed_jobs += 1
                    print(f"ğŸ’¥ å¼‚å¸¸ {job.id}: {e}")
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (self.completed_jobs + self.failed_jobs) / self.total_jobs * 100
                print(f"ğŸ“ˆ è¿›åº¦: {progress:.1f}%")
        
        total_time = time.time() - self.start_time
        print("-" * 50)
        print(f"ğŸ æ‰¹é‡åˆ†æå®Œæˆ")
        print(f"âœ… æˆåŠŸ: {self.completed_jobs}/{self.total_jobs}")
        print(f"âŒ å¤±è´¥: {self.failed_jobs}/{self.total_jobs}")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}s")
        print(f"ğŸ“Š å¹³å‡è€—æ—¶: {total_time/self.total_jobs:.2f}s/ä»»åŠ¡")
        
        return results
    
    def save_results(self, results: List[Dict[str, Any]], output_file: str):
        """ä¿å­˜åˆ†æç»“æœ"""
        print(f"ğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_file}")
        
        if output_file.endswith('.json'):
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
        elif output_file.endswith('.csv'):
            self._save_results_csv(results, output_file)
        else:
            # é»˜è®¤ä¿å­˜ä¸ºJSON
            with open(output_file + '.json', 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜")
    
    def _save_results_csv(self, results: List[Dict[str, Any]], output_file: str):
        """ä¿å­˜ç»“æœä¸ºCSVæ ¼å¼"""
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            
            # å†™å…¥æ ‡é¢˜è¡Œ
            headers = [
                'id', 'description', 'moves_count', 'analysis_time',
                'winrate', 'score_mean', 'visits', 'best_move', 'best_move_winrate'
            ]
            writer.writerow(headers)
            
            # å†™å…¥æ•°æ®è¡Œ
            for result in results:
                row = []
                row.append(result.get('id', ''))
                row.append(result.get('job_description', ''))
                row.append(len(result.get('moves', [])))
                row.append(f"{result.get('analysis_time', 0):.3f}")
                
                # æå–æ ¹èŠ‚ç‚¹ä¿¡æ¯
                root_info = result.get('rootInfo', {})
                row.append(f"{root_info.get('winrate', 0):.4f}")
                row.append(f"{root_info.get('scoreMean', 0):.2f}")
                row.append(root_info.get('visits', 0))
                
                # æå–æœ€ä½³ç§»åŠ¨
                move_infos = result.get('moveInfos', [])
                if move_infos:
                    best_move = move_infos[0]
                    row.append(best_move.get('move', ''))
                    row.append(f"{best_move.get('winrate', 0):.4f}")
                else:
                    row.append('')
                    row.append('')
                
                writer.writerow(row)


def load_jobs_from_file(input_file: str) -> List[AnalysisJob]:
    """ä»æ–‡ä»¶åŠ è½½åˆ†æä»»åŠ¡"""
    jobs = []
    
    if input_file.endswith('.json'):
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            for item in data:
                job = AnalysisJob(
                    id=item.get('id', f"job_{len(jobs)}"),
                    moves=item.get('moves', []),
                    board_size=item.get('board_size', 19),
                    komi=item.get('komi', 7.5),
                    rules=item.get('rules', 'tromp-taylor'),
                    max_visits=item.get('max_visits', 1000),
                    description=item.get('description', '')
                )
                jobs.append(job)
    
    elif input_file.endswith('.csv'):
        with open(input_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # è§£æç§»åŠ¨åºåˆ—
                moves_str = row.get('moves', '')
                moves = []
                if moves_str:
                    try:
                        moves = json.loads(moves_str)
                    except:
                        # å°è¯•ç®€å•æ ¼å¼: "B D4, W Q16"
                        for move_str in moves_str.split(','):
                            move_str = move_str.strip()
                            if ' ' in move_str:
                                color, pos = move_str.split(' ', 1)
                                moves.append([color.strip(), pos.strip()])
                
                job = AnalysisJob(
                    id=row.get('id', f"job_{len(jobs)}"),
                    moves=moves,
                    board_size=int(row.get('board_size', 19)),
                    komi=float(row.get('komi', 7.5)),
                    rules=row.get('rules', 'tromp-taylor'),
                    max_visits=int(row.get('max_visits', 1000)),
                    description=row.get('description', '')
                )
                jobs.append(job)
    
    return jobs


def create_sample_jobs() -> List[AnalysisJob]:
    """åˆ›å»ºç¤ºä¾‹åˆ†æä»»åŠ¡"""
    jobs = []
    
    # 1. ç©ºæ£‹ç›˜
    jobs.append(AnalysisJob(
        id="empty_board",
        moves=[],
        description="ç©ºæ£‹ç›˜å¼€å±€åˆ†æ"
    ))
    
    # 2. å„ç§å¼€å±€
    openings = [
        {
            "id": "star_point_opening",
            "moves": [["B", "D4"], ["W", "Q16"], ["B", "Q4"], ["W", "D16"]],
            "description": "å››è§’æ˜Ÿä½å¼€å±€"
        },
        {
            "id": "komoku_opening",
            "moves": [["B", "D4"], ["W", "Q16"], ["B", "R4"], ["W", "C16"]],
            "description": "å°ç›®å¼€å±€"
        },
        {
            "id": "sansan_opening",
            "moves": [["B", "C3"], ["W", "Q16"], ["B", "Q3"], ["W", "C16"]],
            "description": "ä¸‰ä¸‰å¼€å±€"
        },
        {
            "id": "high_approach",
            "moves": [["B", "D4"], ["W", "Q16"], ["B", "Q4"], ["W", "D16"], ["B", "F3"]],
            "description": "é«˜æŒ‚å¼€å±€"
        },
        {
            "id": "low_approach",
            "moves": [["B", "D4"], ["W", "Q16"], ["B", "Q4"], ["W", "D16"], ["B", "F4"]],
            "description": "ä½æŒ‚å¼€å±€"
        }
    ]
    
    for opening in openings:
        jobs.append(AnalysisJob(
            id=opening["id"],
            moves=opening["moves"],
            description=opening["description"]
        ))
    
    # 3. ä¸åŒè®¿é—®æ•°çš„æµ‹è¯•
    for visits in [100, 500, 1000, 2000]:
        jobs.append(AnalysisJob(
            id=f"visits_test_{visits}",
            moves=[["B", "D4"], ["W", "Q16"]],
            max_visits=visits,
            description=f"è®¿é—®æ•°æµ‹è¯• - {visits}"
        ))
    
    # 4. ä¸åŒæ£‹ç›˜å¤§å°
    for size in [9, 13, 19]:
        jobs.append(AnalysisJob(
            id=f"board_size_{size}",
            moves=[],
            board_size=size,
            description=f"{size}x{size} æ£‹ç›˜åˆ†æ"
        ))
    
    # 5. ä¸åŒè´´ç›®
    for komi in [0.5, 5.5, 7.5, 9.5]:
        jobs.append(AnalysisJob(
            id=f"komi_{komi}",
            moves=[["B", "D4"], ["W", "Q16"]],
            komi=komi,
            description=f"è´´ç›® {komi} åˆ†æ"
        ))
    
    return jobs


def create_sample_input_file(filename: str):
    """åˆ›å»ºç¤ºä¾‹è¾“å…¥æ–‡ä»¶"""
    jobs = create_sample_jobs()
    
    if filename.endswith('.json'):
        data = []
        for job in jobs:
            data.append({
                "id": job.id,
                "moves": job.moves,
                "board_size": job.board_size,
                "komi": job.komi,
                "rules": job.rules,
                "max_visits": job.max_visits,
                "description": job.description
            })
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    elif filename.endswith('.csv'):
        with open(filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['id', 'moves', 'board_size', 'komi', 'rules', 'max_visits', 'description'])
            
            for job in jobs:
                writer.writerow([
                    job.id,
                    json.dumps(job.moves),
                    job.board_size,
                    job.komi,
                    job.rules,
                    job.max_visits,
                    job.description
                ])
    
    print(f"âœ… ç¤ºä¾‹è¾“å…¥æ–‡ä»¶å·²åˆ›å»º: {filename}")


def main():
    parser = argparse.ArgumentParser(description="KataGo HTTPæ‰¹é‡åˆ†æ")
    parser.add_argument("--host", default="localhost", help="æœåŠ¡å™¨åœ°å€ (é»˜è®¤: localhost)")
    parser.add_argument("--port", type=int, default=8080, help="æœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 8080)")
    parser.add_argument("--input", help="è¾“å…¥æ–‡ä»¶ (JSONæˆ–CSVæ ¼å¼)")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶ (JSONæˆ–CSVæ ¼å¼)")
    parser.add_argument("--workers", type=int, default=4, help="å¹¶å‘å·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤: 4)")
    parser.add_argument("--create-sample", help="åˆ›å»ºç¤ºä¾‹è¾“å…¥æ–‡ä»¶")
    
    args = parser.parse_args()
    
    # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
    if args.create_sample:
        create_sample_input_file(args.create_sample)
        return
    
    print("ğŸš€ KataGo HTTPæ‰¹é‡åˆ†æå·¥å…·")
    print(f"ğŸŒ è¿æ¥åˆ°: http://{args.host}:{args.port}")
    
    try:
        analyzer = BatchAnalyzer(args.host, args.port)
        
        # åŠ è½½ä»»åŠ¡
        if args.input and os.path.exists(args.input):
            print(f"ğŸ“‚ ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡: {args.input}")
            jobs = load_jobs_from_file(args.input)
        else:
            print("ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹ä»»åŠ¡")
            jobs = create_sample_jobs()
        
        if not jobs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°åˆ†æä»»åŠ¡")
            return
        
        # æ‰§è¡Œæ‰¹é‡åˆ†æ
        results = analyzer.analyze_batch(jobs, args.workers)
        
        # ä¿å­˜ç»“æœ
        if args.output:
            analyzer.save_results(results, args.output)
        else:
            # é»˜è®¤è¾“å‡ºæ–‡ä»¶å
            timestamp = int(time.time())
            default_output = f"batch_analysis_results_{timestamp}.json"
            analyzer.save_results(results, default_output)
        
        print("\nğŸ‰ æ‰¹é‡åˆ†æå®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ‰¹é‡åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"ğŸ’¥ æ‰¹é‡åˆ†æå¼‚å¸¸: {e}")


if __name__ == "__main__":
    main()